## Hi there! &#x1F338; &#x1F4AE; &#x1F436; &#x1F31E;

<img align="right" alt="Coding" width="1920" src="https://i.imgur.com/I7xjW2X.jpg">

&#x205F;

I am currently developing FewFiu, the next-generation AI-powered Social media Network. I am very interested in collaborating on coding projects, particularly those related to Machine Learning. At the same time, I need help developing code and ML algorithms.
I am very interested in discussing the uses of ML/AI, focusing on applications that can improve the world. While many may focus on the bad things AI may bring, I want to think of the great things and applying ethics to AI solutions.

&#x205F;

During a discussion session during my MBA program with fellow students, I brought up an example of an AI ethics dilemma. Imagine the scenario where you take a self-driving car from work to home. Everything is going smoothly until a young boy riding his bike suddenly appears in front of the self-driving car.

&#x205F;

<img align="right" alt="AI conundrum" width="400" src="https://i.ibb.co/s2Nj9Ms/AI-conondrum.jpg">

There are only two immediate actions that the self-driving car can take, each yielding a completely different outcome:

1. Abruptly swerve to the left and impact a wall, killing you, the passenger.
2. Break hard, but still hit the bicycle, killing the young boy.

To my surprise, the most common answer given to me was neither 1) nor 2). The most common answers were:  
> "That is a coding problem";
> 
> "The code has to consider that situation so nobody is hurt";
> 
> "That would be bad programming". 

&#x205F;

Accidents happen and machines are not exempt either. The above fictional situation is the conundrum of AI ethics. How would society react to a decision made by a 'machine'?  Who gets to choose who lives and who dies? The machine is instructed to perform in a certain way, but somewhere, a decision is made, either by an algorithm or a defined set of rules. When a human driver is involved in such an event, he/she may be morally responsible to a certain extent. But what will happen when a machine is the vehicle's driver? Will the engineers who designed the algorithm be held accountable for prioritizing saving the life of the self-driving car's passenger over the life of the boy on the bicyle?  

Providing answers like the ones given by my fellow students is not good for the development of AI. These are scenarios that should be discussed and debated by all stakeholders and that have a profound impact on how we design ML/AI algorithms.

I am interested in the ethical implications of AI in my next-generation social media project. This is a very lengthy topic, so I will not address it here.

- ðŸ”­ Iâ€™m currently working on my startup, the next Generation AI Powered Social Media.
- ðŸŒ± Iâ€™m currently learning Scala.
- ðŸ‘¯ Iâ€™m looking to collaborate on coding projects, business development.
- ðŸ¤” Iâ€™m looking for help with coding and business development.
- ðŸ’¬ Ask me about my startup.
- ðŸ“« How to reach me: send me an email <hhiraoka1@gmail.com>
- ðŸ˜„ Pronouns: he/him
- âš¡ Fun fact: I'll think of something and will post it here.
- &#x1F4BB; Main Programming Box: An old Dell PowerEdge R420 server with 2 with 16Mb RAM and 2 SSD in non-raid configuration.
- &#x1F4BE; Storage: I am using idrive.
- &#x2328; Keyboard: The unbeatable Fujitsu Happy Hacking Hybrid Type-S
- &#x1F400; Mouse: Logitech MX Master 2S  

